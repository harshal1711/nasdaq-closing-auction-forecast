{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLdfrsggE04B",
        "outputId": "140465af-75b7-4048-d5e6-673dfbea7ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/df_2.parquet'\n",
        "\n",
        "try:\n",
        "  df = pd.read_parquet(file_path)\n",
        "  print(df.head()) # Display first few rows of the dataframe\n",
        "except FileNotFoundError:\n",
        "  print(f\"Error: File not found at {file_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Wg7BfsFLT4",
        "outputId": "55c1ab03-fd99-459f-aa00-27a78fe5bedc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
            "0         0        0                300             0.0   \n",
            "1         0        0                310             0.0   \n",
            "2         0        0                320             0.0   \n",
            "3         0        0                330             0.0   \n",
            "4         0        0                340             0.0   \n",
            "\n",
            "   imbalance_buy_sell_flag  reference_price  far_price  near_price  bid_price  \\\n",
            "0                        0         1.000241   1.000241    1.000241   1.000026   \n",
            "1                        0         0.999919   0.999919    0.999919   0.999812   \n",
            "2                        0         0.999919   0.999919    0.999919   0.999705   \n",
            "3                        0         0.999812   0.999812    0.999812   0.999705   \n",
            "4                        0         0.999491   0.999491    0.999491   0.999169   \n",
            "\n",
            "   ask_price  ...  auction_signal_strength_mean_0_300  \\\n",
            "0   1.000241  ...                            0.000033   \n",
            "1   0.999919  ...                            0.000033   \n",
            "2   0.999919  ...                            0.000033   \n",
            "3   0.999812  ...                            0.000033   \n",
            "4   0.999383  ...                            0.000033   \n",
            "\n",
            "   auction_signal_strength_std_0_300  stock_vs_index_wap_ratio_min_0_300  \\\n",
            "0                           0.000153                            0.999314   \n",
            "1                           0.000153                            0.999314   \n",
            "2                           0.000153                            0.999314   \n",
            "3                           0.000153                            0.999314   \n",
            "4                           0.000153                            0.999314   \n",
            "\n",
            "   stock_vs_index_wap_ratio_max_0_300 stock_vs_index_wap_ratio_mean_0_300  \\\n",
            "0                            1.000355                            0.999812   \n",
            "1                            1.000355                            0.999812   \n",
            "2                            1.000355                            0.999812   \n",
            "3                            1.000355                            0.999812   \n",
            "4                            1.000355                            0.999812   \n",
            "\n",
            "   stock_vs_index_wap_ratio_std_0_300  spread_min_0_300  spread_max_0_300  \\\n",
            "0                            0.000225          0.000107          0.000535   \n",
            "1                            0.000225          0.000107          0.000535   \n",
            "2                            0.000225          0.000107          0.000535   \n",
            "3                            0.000225          0.000107          0.000535   \n",
            "4                            0.000225          0.000107          0.000535   \n",
            "\n",
            "   spread_mean_0_300  spread_std_0_300  \n",
            "0           0.000171          0.000091  \n",
            "1           0.000171          0.000091  \n",
            "2           0.000171          0.000091  \n",
            "3           0.000171          0.000091  \n",
            "4           0.000171          0.000091  \n",
            "\n",
            "[5 rows x 140 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Special value for masking\n",
        "SPECIAL_VALUE = -999.0\n",
        "df['far_price'] = df.groupby('stock_id')['far_price'].ffill()\n",
        "df['far_price'] = df['far_price'].fillna(1)"
      ],
      "metadata": {
        "id": "per1wF1bKyRO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Find columns with nans and number\n",
        "\n",
        "# Find columns with NaNs and their counts\n",
        "nan_counts = df.isna().sum()\n",
        "nan_cols = nan_counts[nan_counts > 0]\n",
        "\n",
        "print(\"Columns with NaN values:\\n\", nan_cols)\n",
        "\n",
        "# Number of columns with NaNs\n",
        "num_nan_cols = len(nan_cols)\n",
        "print(\"\\nNumber of columns with NaN values:\", num_nan_cols)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoIy27w2OEdW",
        "outputId": "047516d0-a3aa-4f65-a81c-23b22419aba5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with NaN values:\n",
            " Series([], dtype: int64)\n",
            "\n",
            "Number of columns with NaN values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test sets\n",
        "train_df = df[df['date_id'] <= 400].copy()\n",
        "test_df = df[df['date_id'] > 400].copy()\n",
        "\n",
        "# Print summary\n",
        "print(f\"Train days: {train_df['date_id'].min()} to {train_df['date_id'].max()} -> {train_df.shape}\")\n",
        "print(f\"Test days: {test_df['date_id'].min()} to {test_df['date_id'].max()} -> {test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYG-kO-CFXo1",
        "outputId": "e511bc3a-e39c-4363-a5df-441354ccc010"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train days: 0 to 400 -> (1397376, 140)\n",
            "Test days: 401 to 480 -> (282240, 140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj25BDEiJPDr",
        "outputId": "3fcadd18-08fc-417d-863c-0d36584bc3a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
              "       'imbalance_buy_sell_flag', 'reference_price', 'far_price', 'near_price',\n",
              "       'bid_price', 'ask_price',\n",
              "       ...\n",
              "       'auction_signal_strength_mean_0_300',\n",
              "       'auction_signal_strength_std_0_300',\n",
              "       'stock_vs_index_wap_ratio_min_0_300',\n",
              "       'stock_vs_index_wap_ratio_max_0_300',\n",
              "       'stock_vs_index_wap_ratio_mean_0_300',\n",
              "       'stock_vs_index_wap_ratio_std_0_300', 'spread_min_0_300',\n",
              "       'spread_max_0_300', 'spread_mean_0_300', 'spread_std_0_300'],\n",
              "      dtype='object', length=140)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ----- 1. Separate features & target -----\n",
        "target_col = 'target'  # Replace with your actual target\n",
        "exclude_cols = ['date_id', 'time_id', 'target', 'seconds_in_bucket']  # Add others if needed\n",
        "\n",
        "# All columns except target & known categorical/time identifiers\n",
        "feature_cols = [col for col in train_df.columns if col not in exclude_cols]\n",
        "\n",
        "# ----- 2. Identify numeric & categorical -----\n",
        "categorical_cols = ['stock_id']\n",
        "do_not_scale = ['imbalance_buy_sell_flag']\n",
        "numeric_cols = [col for col in feature_cols if col not in categorical_cols]\n",
        "scale_cols = [col for col in numeric_cols if col not in do_not_scale]\n",
        "\n",
        "# ----- 3. Scale numeric features -----\n",
        "scaler = StandardScaler()\n",
        "train_df[scale_cols] = scaler.fit_transform(train_df[scale_cols])\n",
        "test_df[scale_cols] = scaler.transform(test_df[scale_cols])\n",
        "\n",
        "# for col in scale_cols:\n",
        "#     valid_train = train_df[col] != SPECIAL_VALUE\n",
        "#     valid_test = test_df[col] != SPECIAL_VALUE\n",
        "\n",
        "#     scaled_train = scaler.fit_transform(train_df.loc[valid_train, [col]]).astype(np.float32).flatten()\n",
        "#     scaled_test = scaler.transform(test_df.loc[valid_test, [col]]).astype(np.float32).flatten()\n",
        "\n",
        "#     # Ensure the column is float first to prevent assignment issues\n",
        "#     train_df[col] = train_df[col].astype(np.float32)\n",
        "#     test_df[col] = test_df[col].astype(np.float32)\n",
        "\n",
        "#     train_df.loc[valid_train, col] = scaled_train\n",
        "#     test_df.loc[valid_test, col] = scaled_test\n"
      ],
      "metadata": {
        "id": "TrOgFiprF2E_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.copy()\n",
        "test_df = test_df.copy()"
      ],
      "metadata": {
        "id": "9-4-37P5F6uE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def reshape_to_tensor(df, feature_cols, target_col='target', timesteps_per_day=18):\n",
        "    \"\"\"\n",
        "    Converts a long-form DataFrame into (X, y) tensors for GRU sequence-to-sequence learning.\n",
        "\n",
        "    Args:\n",
        "        df: pandas DataFrame with 'stock_id', 'date_id', 'seconds_in_bucket', features, and target\n",
        "        feature_cols: list of column names to be used as input features\n",
        "        target_col: name of the column to use as target\n",
        "        timesteps_per_day: number of time intervals per day (default: 30)\n",
        "\n",
        "    Returns:\n",
        "        X: np.array of shape (N_samples, 30, num_features)\n",
        "        y: np.array of shape (N_samples, 30)\n",
        "        keys: list of tuples (stock_id, date_id) representing each sample\n",
        "    \"\"\"\n",
        "    grouped = df.groupby(['stock_id', 'date_id'])\n",
        "    X_list, y_list, keys = [], [], []\n",
        "\n",
        "    for (stock_id, date_id), group in grouped:\n",
        "        group_sorted = group.sort_values('seconds_in_bucket')\n",
        "        if len(group_sorted) != timesteps_per_day:\n",
        "            # print(stock_id)\n",
        "            continue  # skip incomplete days\n",
        "\n",
        "        X_seq = group_sorted[feature_cols].values  # shape: (30, F)\n",
        "        y_seq = group_sorted[target_col].values    # shape: (30,)\n",
        "\n",
        "        X_list.append(X_seq)\n",
        "        y_list.append(y_seq)\n",
        "        keys.append((stock_id, date_id))\n",
        "\n",
        "    X = np.stack(X_list)  # shape: (N, 30, F)\n",
        "    y = np.stack(y_list)  # shape: (N, 30)\n",
        "    return X, y, keys\n"
      ],
      "metadata": {
        "id": "c9X3hESXF-Ix"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y, train_keys = reshape_to_tensor(train_df, feature_cols)\n",
        "test_X, test_y, test_keys = reshape_to_tensor(test_df, feature_cols)"
      ],
      "metadata": {
        "id": "Ww8ptGckGGu4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape\n",
        "# test_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eWPqc-mGKMl",
        "outputId": "e65d0756-37fe-469d-96cc-45e629a9c96d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77632, 18, 136)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape\n",
        "test_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9rT4ChOHk8u",
        "outputId": "6cd1b9d4-0710-4de6-80fe-a531ec6ce031"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15680, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import TimeDistributed, Masking\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "-ZihN-G5GOS8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Time-Based Cross-Validation Split Function ---\n",
        "def time_based_cv(df, group_col='date_id', n_splits=5):\n",
        "    unique_dates = sorted(df[group_col].unique())\n",
        "    split_size = len(unique_dates) // (n_splits + 1)\n",
        "    for i in range(1, n_splits + 1):\n",
        "        train_days = unique_dates[: i * split_size]\n",
        "        test_days = unique_dates[i * split_size : (i + 1) * split_size]\n",
        "        train_idx = df[df[group_col].isin(train_days)].index\n",
        "        test_idx = df[df[group_col].isin(test_days)].index\n",
        "        yield train_idx, test_idx\n",
        "\n",
        "def build_gru_model(n_layers=1, input_shape=(18, 136), dropout=0.2):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=input_shape))\n",
        "    for i in range(n_layers):\n",
        "        return_seq = True  # we want return_sequences=True in all layers\n",
        "        model.add(GRU(64, return_sequences=return_seq))\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(TimeDistributed(Dense(1)))\n",
        "    model.compile(optimizer='adam', loss='mae')\n",
        "    return model"
      ],
      "metadata": {
        "id": "cHmkPWJnGUpw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hyperparameter Search ---\n",
        "def run_time_cv_gru(train_X, train_y, df_train_keys, layer_choices=[1, 2, 3, 4]):\n",
        "    results = {}\n",
        "    for n_layers in layer_choices:\n",
        "        print(f\"\\nTraining model with {n_layers} GRU layer(s)...\")\n",
        "        fold = 0\n",
        "        fold_mae = []\n",
        "        for train_idx, val_idx in time_based_cv(df_train_keys, group_col='date_id', n_splits=5):\n",
        "            fold += 1\n",
        "            print(f\"\\nFold {fold}\")\n",
        "            X_train, X_val = train_X[train_idx], train_X[val_idx]\n",
        "            y_train, y_val = train_y[train_idx], train_y[val_idx]\n",
        "\n",
        "            model = build_gru_model(n_layers=n_layers, input_shape=(train_X.shape[1], train_X.shape[2]))\n",
        "            es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "            model.fit(X_train, y_train,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      epochs=100,\n",
        "                      batch_size=32,\n",
        "                      callbacks=[es],\n",
        "                      verbose=1)\n",
        "\n",
        "            preds = model.predict(X_val)\n",
        "            mae = mean_absolute_error(y_val.flatten(), preds.flatten())\n",
        "            print(f\"Fold {fold} MAE: {mae:.5f}\")\n",
        "            fold_mae.append(mae)\n",
        "\n",
        "        results[n_layers] = np.mean(fold_mae)\n",
        "        print(f\"Average MAE for {n_layers} layer(s): {results[n_layers]:.5f}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "F1tE45FVGXce"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_keys_df = pd.DataFrame(train_keys, columns=[\"stock_id\", \"date_id\"])"
      ],
      "metadata": {
        "id": "kXqCq4uhGcOL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqvMNaUYR1El"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = run_time_cv_gru(train_X, train_y, train_keys_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k84-joQRGeBe",
        "outputId": "04cdbe24-34e3-4e20-c30f-47a9dcbb2dc0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with 1 GRU layer(s)...\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 4.8191 - val_loss: 6.2736\n",
            "Epoch 2/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.7085 - val_loss: 6.2499\n",
            "Epoch 3/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.6750 - val_loss: 6.2839\n",
            "Epoch 4/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.6578 - val_loss: 6.2398\n",
            "Epoch 5/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.6222 - val_loss: 6.2443\n",
            "Epoch 6/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.6199 - val_loss: 6.2384\n",
            "Epoch 7/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.6558 - val_loss: 6.2490\n",
            "Epoch 8/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.6562 - val_loss: 6.2371\n",
            "Epoch 9/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.5509 - val_loss: 6.2494\n",
            "Epoch 10/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.5844 - val_loss: 6.2752\n",
            "Epoch 11/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.5788 - val_loss: 6.2694\n",
            "Epoch 12/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.5428 - val_loss: 6.2688\n",
            "Epoch 13/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.5382 - val_loss: 6.2837\n",
            "Epoch 14/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.5485 - val_loss: 6.3028\n",
            "Epoch 15/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.5367 - val_loss: 6.3057\n",
            "Epoch 16/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.5088 - val_loss: 6.3376\n",
            "Epoch 17/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 4.5117 - val_loss: 6.3284\n",
            "Epoch 18/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 4.4242 - val_loss: 6.3391\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Fold 1 MAE: 6.23713\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 5.5438 - val_loss: 6.4401\n",
            "Epoch 2/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4534 - val_loss: 6.4147\n",
            "Epoch 3/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4950 - val_loss: 6.4114\n",
            "Epoch 4/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4128 - val_loss: 6.4070\n",
            "Epoch 5/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4725 - val_loss: 6.4021\n",
            "Epoch 6/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4667 - val_loss: 6.4120\n",
            "Epoch 7/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4164 - val_loss: 6.4066\n",
            "Epoch 8/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3988 - val_loss: 6.4077\n",
            "Epoch 9/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.4004 - val_loss: 6.4123\n",
            "Epoch 10/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3468 - val_loss: 6.4252\n",
            "Epoch 11/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3496 - val_loss: 6.4274\n",
            "Epoch 12/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3251 - val_loss: 6.4360\n",
            "Epoch 13/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3248 - val_loss: 6.4642\n",
            "Epoch 14/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.2868 - val_loss: 6.4527\n",
            "Epoch 15/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.2772 - val_loss: 6.4878\n",
            "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Fold 2 MAE: 6.40215\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.8680 - val_loss: 5.7840\n",
            "Epoch 2/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7779 - val_loss: 5.7602\n",
            "Epoch 3/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7704 - val_loss: 5.7764\n",
            "Epoch 4/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7493 - val_loss: 5.7523\n",
            "Epoch 5/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7520 - val_loss: 5.7536\n",
            "Epoch 6/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7387 - val_loss: 5.7570\n",
            "Epoch 7/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7329 - val_loss: 5.7591\n",
            "Epoch 8/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7013 - val_loss: 5.7556\n",
            "Epoch 9/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.7023 - val_loss: 5.7717\n",
            "Epoch 10/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.6999 - val_loss: 5.7604\n",
            "Epoch 11/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.6583 - val_loss: 5.7782\n",
            "Epoch 12/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.6592 - val_loss: 5.7836\n",
            "Epoch 13/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.6429 - val_loss: 5.7939\n",
            "Epoch 14/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 5.6369 - val_loss: 5.7978\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Fold 3 MAE: 5.75227\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.8254 - val_loss: 5.6113\n",
            "Epoch 2/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7483 - val_loss: 5.6122\n",
            "Epoch 3/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7522 - val_loss: 5.6051\n",
            "Epoch 4/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7749 - val_loss: 5.6018\n",
            "Epoch 5/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7148 - val_loss: 5.6050\n",
            "Epoch 6/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7242 - val_loss: 5.6113\n",
            "Epoch 7/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7107 - val_loss: 5.6097\n",
            "Epoch 8/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.7116 - val_loss: 5.6140\n",
            "Epoch 9/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.6818 - val_loss: 5.6109\n",
            "Epoch 10/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.6657 - val_loss: 5.6280\n",
            "Epoch 11/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.6573 - val_loss: 5.6296\n",
            "Epoch 12/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.6375 - val_loss: 5.6278\n",
            "Epoch 13/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.6725 - val_loss: 5.6267\n",
            "Epoch 14/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 5.6450 - val_loss: 5.6417\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Fold 4 MAE: 5.60184\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - loss: 5.8129 - val_loss: 5.5413\n",
            "Epoch 2/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.7296 - val_loss: 5.5242\n",
            "Epoch 3/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.7222 - val_loss: 5.5343\n",
            "Epoch 4/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.7442 - val_loss: 5.5141\n",
            "Epoch 5/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.7048 - val_loss: 5.5692\n",
            "Epoch 6/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 5.6805 - val_loss: 5.5263\n",
            "Epoch 7/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 5.6831 - val_loss: 5.5187\n",
            "Epoch 8/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.6951 - val_loss: 5.5242\n",
            "Epoch 9/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.6573 - val_loss: 5.5361\n",
            "Epoch 10/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.6712 - val_loss: 5.5268\n",
            "Epoch 11/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.6662 - val_loss: 5.5278\n",
            "Epoch 12/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.6214 - val_loss: 5.5319\n",
            "Epoch 13/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - loss: 5.6216 - val_loss: 5.5316\n",
            "Epoch 14/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 5.6306 - val_loss: 5.5392\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Fold 5 MAE: 5.51406\n",
            "Average MAE for 1 layer(s): 5.90149\n",
            "\n",
            "Training model with 2 GRU layer(s)...\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 4.8350 - val_loss: 6.2714\n",
            "Epoch 2/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.7302 - val_loss: 6.2511\n",
            "Epoch 3/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6479 - val_loss: 6.2467\n",
            "Epoch 4/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6922 - val_loss: 6.2426\n",
            "Epoch 5/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.7153 - val_loss: 6.2409\n",
            "Epoch 6/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6442 - val_loss: 6.2383\n",
            "Epoch 7/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6430 - val_loss: 6.2466\n",
            "Epoch 8/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.6364 - val_loss: 6.2558\n",
            "Epoch 9/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6122 - val_loss: 6.2658\n",
            "Epoch 10/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6011 - val_loss: 6.3017\n",
            "Epoch 11/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.5657 - val_loss: 6.3057\n",
            "Epoch 12/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.5826 - val_loss: 6.3272\n",
            "Epoch 13/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.5493 - val_loss: 6.3295\n",
            "Epoch 14/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.5654 - val_loss: 6.3335\n",
            "Epoch 15/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.5130 - val_loss: 6.3634\n",
            "Epoch 16/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.5382 - val_loss: 6.4073\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 1 MAE: 6.23828\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 5.5568 - val_loss: 6.4281\n",
            "Epoch 2/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.4508 - val_loss: 6.4140\n",
            "Epoch 3/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.4844 - val_loss: 6.4137\n",
            "Epoch 4/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.4498 - val_loss: 6.3980\n",
            "Epoch 5/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.4827 - val_loss: 6.4158\n",
            "Epoch 6/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.4163 - val_loss: 6.4331\n",
            "Epoch 7/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.3836 - val_loss: 6.4018\n",
            "Epoch 8/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3904 - val_loss: 6.4114\n",
            "Epoch 9/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3919 - val_loss: 6.4309\n",
            "Epoch 10/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3636 - val_loss: 6.4140\n",
            "Epoch 11/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3289 - val_loss: 6.4435\n",
            "Epoch 12/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3280 - val_loss: 6.4750\n",
            "Epoch 13/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 5.3043 - val_loss: 6.4581\n",
            "Epoch 14/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 5.3454 - val_loss: 6.4752\n",
            "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 2 MAE: 6.39797\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 5.8612 - val_loss: 5.7636\n",
            "Epoch 2/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.7721 - val_loss: 5.7589\n",
            "Epoch 3/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.7487 - val_loss: 5.7582\n",
            "Epoch 4/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.7602 - val_loss: 5.7528\n",
            "Epoch 5/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - loss: 5.7462 - val_loss: 5.7474\n",
            "Epoch 6/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.7013 - val_loss: 5.7696\n",
            "Epoch 7/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6937 - val_loss: 5.7609\n",
            "Epoch 8/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.7328 - val_loss: 5.7497\n",
            "Epoch 9/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6821 - val_loss: 5.7509\n",
            "Epoch 10/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6674 - val_loss: 5.7632\n",
            "Epoch 11/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6560 - val_loss: 5.7700\n",
            "Epoch 12/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6985 - val_loss: 5.7800\n",
            "Epoch 13/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6816 - val_loss: 5.7648\n",
            "Epoch 14/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6823 - val_loss: 5.7873\n",
            "Epoch 15/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - loss: 5.6298 - val_loss: 5.7841\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 3 MAE: 5.74742\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - loss: 5.8793 - val_loss: 5.6101\n",
            "Epoch 2/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 5.7882 - val_loss: 5.6035\n",
            "Epoch 3/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 5.7395 - val_loss: 5.6032\n",
            "Epoch 4/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.7150 - val_loss: 5.6078\n",
            "Epoch 5/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.7558 - val_loss: 5.6156\n",
            "Epoch 6/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.7203 - val_loss: 5.6067\n",
            "Epoch 7/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.6815 - val_loss: 5.6079\n",
            "Epoch 8/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.7101 - val_loss: 5.6311\n",
            "Epoch 9/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 5.6958 - val_loss: 5.6167\n",
            "Epoch 10/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 5.7162 - val_loss: 5.6187\n",
            "Epoch 11/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - loss: 5.6641 - val_loss: 5.6196\n",
            "Epoch 12/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.6872 - val_loss: 5.6203\n",
            "Epoch 13/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 5.6574 - val_loss: 5.6227\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 4 MAE: 5.60325\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - loss: 5.8005 - val_loss: 5.5306\n",
            "Epoch 2/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.7303 - val_loss: 5.5223\n",
            "Epoch 3/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.7149 - val_loss: 5.5165\n",
            "Epoch 4/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.7076 - val_loss: 5.5152\n",
            "Epoch 5/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.7086 - val_loss: 5.5416\n",
            "Epoch 6/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.7257 - val_loss: 5.5141\n",
            "Epoch 7/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6830 - val_loss: 5.5158\n",
            "Epoch 8/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6904 - val_loss: 5.5222\n",
            "Epoch 9/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6834 - val_loss: 5.5193\n",
            "Epoch 10/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6676 - val_loss: 5.5256\n",
            "Epoch 11/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6383 - val_loss: 5.5236\n",
            "Epoch 12/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6520 - val_loss: 5.5475\n",
            "Epoch 13/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6831 - val_loss: 5.5385\n",
            "Epoch 14/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6272 - val_loss: 5.5330\n",
            "Epoch 15/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6343 - val_loss: 5.5398\n",
            "Epoch 16/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 5.6135 - val_loss: 5.5489\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 5 MAE: 5.51408\n",
            "Average MAE for 2 layer(s): 5.90020\n",
            "\n",
            "Training model with 3 GRU layer(s)...\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 4.7760 - val_loss: 6.2998\n",
            "Epoch 2/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 4.7161 - val_loss: 6.2474\n",
            "Epoch 3/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.7051 - val_loss: 6.2374\n",
            "Epoch 4/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.7492 - val_loss: 6.2412\n",
            "Epoch 5/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - loss: 4.6869 - val_loss: 6.2412\n",
            "Epoch 6/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.6376 - val_loss: 6.2454\n",
            "Epoch 7/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.6234 - val_loss: 6.2540\n",
            "Epoch 8/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.6408 - val_loss: 6.2899\n",
            "Epoch 9/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.6205 - val_loss: 6.2578\n",
            "Epoch 10/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.6314 - val_loss: 6.2823\n",
            "Epoch 11/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.5833 - val_loss: 6.3535\n",
            "Epoch 12/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.5704 - val_loss: 6.2974\n",
            "Epoch 13/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 4.5420 - val_loss: 6.3268\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Fold 1 MAE: 6.23737\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 5.5521 - val_loss: 6.4530\n",
            "Epoch 2/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - loss: 5.4941 - val_loss: 6.4143\n",
            "Epoch 3/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 5.5286 - val_loss: 6.4030\n",
            "Epoch 4/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.4307 - val_loss: 6.4161\n",
            "Epoch 5/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.4329 - val_loss: 6.4305\n",
            "Epoch 6/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 5.3755 - val_loss: 6.4234\n",
            "Epoch 7/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.4096 - val_loss: 6.4169\n",
            "Epoch 8/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.4150 - val_loss: 6.4271\n",
            "Epoch 9/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 5.3599 - val_loss: 6.4061\n",
            "Epoch 10/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.3896 - val_loss: 6.4411\n",
            "Epoch 11/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 5.3723 - val_loss: 6.4514\n",
            "Epoch 12/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.3425 - val_loss: 6.4350\n",
            "Epoch 13/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 5.3554 - val_loss: 6.4808\n",
            "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Fold 2 MAE: 6.40298\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 5.8475 - val_loss: 5.7689\n",
            "Epoch 2/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7825 - val_loss: 5.7678\n",
            "Epoch 3/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.8026 - val_loss: 5.7672\n",
            "Epoch 4/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7452 - val_loss: 5.7520\n",
            "Epoch 5/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7741 - val_loss: 5.7443\n",
            "Epoch 6/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7527 - val_loss: 5.7474\n",
            "Epoch 7/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7218 - val_loss: 5.7535\n",
            "Epoch 8/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7086 - val_loss: 5.7505\n",
            "Epoch 9/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6810 - val_loss: 5.7641\n",
            "Epoch 10/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.7008 - val_loss: 5.7595\n",
            "Epoch 11/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6928 - val_loss: 5.7621\n",
            "Epoch 12/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6454 - val_loss: 5.7748\n",
            "Epoch 13/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6800 - val_loss: 5.7637\n",
            "Epoch 14/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6411 - val_loss: 5.7914\n",
            "Epoch 15/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - loss: 5.6195 - val_loss: 5.7786\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Fold 3 MAE: 5.74431\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 5.8248 - val_loss: 5.6126\n",
            "Epoch 2/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.8044 - val_loss: 5.6159\n",
            "Epoch 3/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7442 - val_loss: 5.6102\n",
            "Epoch 4/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7637 - val_loss: 5.6051\n",
            "Epoch 5/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7352 - val_loss: 5.6162\n",
            "Epoch 6/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7208 - val_loss: 5.6290\n",
            "Epoch 7/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7602 - val_loss: 5.6040\n",
            "Epoch 8/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6701 - val_loss: 5.6163\n",
            "Epoch 9/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7325 - val_loss: 5.6111\n",
            "Epoch 10/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.7077 - val_loss: 5.6155\n",
            "Epoch 11/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6429 - val_loss: 5.6132\n",
            "Epoch 12/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6402 - val_loss: 5.6321\n",
            "Epoch 13/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6543 - val_loss: 5.6223\n",
            "Epoch 14/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6319 - val_loss: 5.6316\n",
            "Epoch 15/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6365 - val_loss: 5.6426\n",
            "Epoch 16/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 5.6614 - val_loss: 5.6275\n",
            "Epoch 17/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 5.6340 - val_loss: 5.6465\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Fold 4 MAE: 5.60403\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 5.7921 - val_loss: 5.5262\n",
            "Epoch 2/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 5.7303 - val_loss: 5.5226\n",
            "Epoch 3/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 5.7633 - val_loss: 5.5178\n",
            "Epoch 4/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.7289 - val_loss: 5.5183\n",
            "Epoch 5/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.7111 - val_loss: 5.5165\n",
            "Epoch 6/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 5.6690 - val_loss: 5.5219\n",
            "Epoch 7/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 5.7053 - val_loss: 5.5253\n",
            "Epoch 8/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6685 - val_loss: 5.5238\n",
            "Epoch 9/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - loss: 5.6634 - val_loss: 5.5213\n",
            "Epoch 10/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6758 - val_loss: 5.5206\n",
            "Epoch 11/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6720 - val_loss: 5.5198\n",
            "Epoch 12/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6648 - val_loss: 5.5272\n",
            "Epoch 13/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6411 - val_loss: 5.5613\n",
            "Epoch 14/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6752 - val_loss: 5.5456\n",
            "Epoch 15/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - loss: 5.6437 - val_loss: 5.5289\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "Fold 5 MAE: 5.51651\n",
            "Average MAE for 3 layer(s): 5.90104\n",
            "\n",
            "Training model with 4 GRU layer(s)...\n",
            "\n",
            "Fold 1\n",
            "Epoch 1/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - loss: 4.8145 - val_loss: 6.2976\n",
            "Epoch 2/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.7420 - val_loss: 6.2550\n",
            "Epoch 3/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.7152 - val_loss: 6.2398\n",
            "Epoch 4/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.6495 - val_loss: 6.2395\n",
            "Epoch 5/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.6585 - val_loss: 6.2536\n",
            "Epoch 6/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.7049 - val_loss: 6.2437\n",
            "Epoch 7/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.6366 - val_loss: 6.2374\n",
            "Epoch 8/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.6081 - val_loss: 6.2693\n",
            "Epoch 9/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.6664 - val_loss: 6.2610\n",
            "Epoch 10/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.6506 - val_loss: 6.2580\n",
            "Epoch 11/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.5603 - val_loss: 6.3110\n",
            "Epoch 12/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.6221 - val_loss: 6.3229\n",
            "Epoch 13/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.6049 - val_loss: 6.3181\n",
            "Epoch 14/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.5633 - val_loss: 6.3651\n",
            "Epoch 15/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 4.5361 - val_loss: 6.3659\n",
            "Epoch 16/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.5737 - val_loss: 6.3880\n",
            "Epoch 17/100\n",
            "\u001b[1m390/390\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 4.4539 - val_loss: 6.4080\n",
            "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Fold 1 MAE: 6.23735\n",
            "\n",
            "Fold 2\n",
            "Epoch 1/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13ms/step - loss: 5.5842 - val_loss: 6.4507\n",
            "Epoch 2/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.4650 - val_loss: 6.4154\n",
            "Epoch 3/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.4976 - val_loss: 6.4104\n",
            "Epoch 4/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.4651 - val_loss: 6.4120\n",
            "Epoch 5/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.4835 - val_loss: 6.4112\n",
            "Epoch 6/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 5.4581 - val_loss: 6.4210\n",
            "Epoch 7/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 5.4576 - val_loss: 6.4461\n",
            "Epoch 8/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.4130 - val_loss: 6.4122\n",
            "Epoch 9/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 5.4548 - val_loss: 6.4232\n",
            "Epoch 10/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 5.3845 - val_loss: 6.4376\n",
            "Epoch 11/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.3950 - val_loss: 6.4478\n",
            "Epoch 12/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.3897 - val_loss: 6.4193\n",
            "Epoch 13/100\n",
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 5.3608 - val_loss: 6.4458\n",
            "\u001b[1m399/399\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
            "Fold 2 MAE: 6.41043\n",
            "\n",
            "Fold 3\n",
            "Epoch 1/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - loss: 5.9054 - val_loss: 5.7752\n",
            "Epoch 2/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.8050 - val_loss: 5.7680\n",
            "Epoch 3/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.7580 - val_loss: 5.7727\n",
            "Epoch 4/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.7368 - val_loss: 5.7522\n",
            "Epoch 5/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.7539 - val_loss: 5.7498\n",
            "Epoch 6/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.7099 - val_loss: 5.7665\n",
            "Epoch 7/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.7391 - val_loss: 5.7503\n",
            "Epoch 8/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.7012 - val_loss: 5.7991\n",
            "Epoch 9/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 5.6695 - val_loss: 5.7668\n",
            "Epoch 10/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 5.6678 - val_loss: 5.7990\n",
            "Epoch 11/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.6714 - val_loss: 5.8100\n",
            "Epoch 12/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.6488 - val_loss: 5.7843\n",
            "Epoch 13/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step - loss: 5.6438 - val_loss: 5.7977\n",
            "Epoch 14/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - loss: 5.6177 - val_loss: 5.8268\n",
            "Epoch 15/100\n",
            "\u001b[1m1186/1186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - loss: 5.5957 - val_loss: 5.7808\n",
            "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Fold 3 MAE: 5.74982\n",
            "\n",
            "Fold 4\n",
            "Epoch 1/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 5.8784 - val_loss: 5.6145\n",
            "Epoch 2/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 5.7802 - val_loss: 5.6113\n",
            "Epoch 3/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 5.7674 - val_loss: 5.6004\n",
            "Epoch 4/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.7698 - val_loss: 5.6067\n",
            "Epoch 5/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.7160 - val_loss: 5.6183\n",
            "Epoch 6/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.7603 - val_loss: 5.6082\n",
            "Epoch 7/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.7327 - val_loss: 5.6048\n",
            "Epoch 8/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.7349 - val_loss: 5.6218\n",
            "Epoch 9/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.7094 - val_loss: 5.6108\n",
            "Epoch 10/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 5.6865 - val_loss: 5.6193\n",
            "Epoch 11/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 5.6772 - val_loss: 5.6115\n",
            "Epoch 12/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 5.6858 - val_loss: 5.6498\n",
            "Epoch 13/100\n",
            "\u001b[1m1588/1588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - loss: 5.6508 - val_loss: 5.6284\n",
            "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Fold 4 MAE: 5.60042\n",
            "\n",
            "Fold 5\n",
            "Epoch 1/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - loss: 5.8162 - val_loss: 5.5345\n",
            "Epoch 2/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 5.7347 - val_loss: 5.5202\n",
            "Epoch 3/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 5.7155 - val_loss: 5.5176\n",
            "Epoch 4/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 5.7099 - val_loss: 5.5227\n",
            "Epoch 5/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 5.6960 - val_loss: 5.5280\n",
            "Epoch 6/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 5.7178 - val_loss: 5.5193\n",
            "Epoch 7/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 5.6676 - val_loss: 5.5242\n",
            "Epoch 8/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 5.6817 - val_loss: 5.5185\n",
            "Epoch 9/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 5.6764 - val_loss: 5.5381\n",
            "Epoch 10/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 5.6509 - val_loss: 5.5312\n",
            "Epoch 11/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - loss: 5.6677 - val_loss: 5.5291\n",
            "Epoch 12/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 5.6584 - val_loss: 5.5409\n",
            "Epoch 13/100\n",
            "\u001b[1m1992/1992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - loss: 5.6414 - val_loss: 5.5396\n",
            "\u001b[1m405/405\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "Fold 5 MAE: 5.51757\n",
            "Average MAE for 4 layer(s): 5.90312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_layers = min(results, key=results.get)\n",
        "print(f\"Best # of layers: {best_layers}, MAE: {results[best_layers]:.5f}\")\n",
        "\n",
        "# Rebuild and retrain on full data\n",
        "final_model = build_gru_model(n_layers=best_layers, input_shape=(train_X.shape[1], train_X.shape[2]))\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "final_model.fit(train_X, train_y,\n",
        "                validation_split=0.1,  # optional small holdout for early stopping\n",
        "                epochs=100,\n",
        "                batch_size=32,\n",
        "                callbacks=[es],\n",
        "                verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhiyBsdZWEF4",
        "outputId": "68b3b948-76d9-473e-9d00-fb0730e56e0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best # of layers: 2, MAE: 5.90020\n",
            "Epoch 1/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 8ms/step - loss: 5.8224 - val_loss: 5.2397\n",
            "Epoch 2/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.7841 - val_loss: 5.2372\n",
            "Epoch 3/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.7485 - val_loss: 5.2254\n",
            "Epoch 4/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.7182 - val_loss: 5.2341\n",
            "Epoch 5/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.7128 - val_loss: 5.2244\n",
            "Epoch 6/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.6956 - val_loss: 5.2158\n",
            "Epoch 7/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.6904 - val_loss: 5.2243\n",
            "Epoch 8/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.6846 - val_loss: 5.2166\n",
            "Epoch 9/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6759 - val_loss: 5.2164\n",
            "Epoch 10/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6933 - val_loss: 5.2186\n",
            "Epoch 11/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6773 - val_loss: 5.2243\n",
            "Epoch 12/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6652 - val_loss: 5.2111\n",
            "Epoch 13/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6590 - val_loss: 5.2118\n",
            "Epoch 14/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6643 - val_loss: 5.2224\n",
            "Epoch 15/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.6417 - val_loss: 5.2118\n",
            "Epoch 16/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6416 - val_loss: 5.2134\n",
            "Epoch 17/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6244 - val_loss: 5.2184\n",
            "Epoch 18/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.6143 - val_loss: 5.2148\n",
            "Epoch 19/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - loss: 5.5974 - val_loss: 5.2184\n",
            "Epoch 20/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.5796 - val_loss: 5.2135\n",
            "Epoch 21/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.5990 - val_loss: 5.2144\n",
            "Epoch 22/100\n",
            "\u001b[1m2184/2184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 5.5805 - val_loss: 5.2276\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fd6c5191d90>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model.save('/content/drive/MyDrive/best_gru_model2.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGbg42-IWTaK",
        "outputId": "760954c5-d960-4b45-813c-c92016d4ebdd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "\n",
        "final_model = tf.keras.models.load_model(\n",
        "    '/content/drive/MyDrive/best_gru_model2.h5',\n",
        "    custom_objects={'mae': MeanAbsoluteError()}\n",
        ")\n",
        "\n",
        "\n",
        "# Make predictions on holdout test set\n",
        "test_preds = final_model.predict(test_X)\n",
        "\n",
        "test_mae = mean_absolute_error(test_y.flatten(), test_preds.flatten())\n",
        "print(f\"Test MAE on holdout: {test_mae:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQImDpTAWYsj",
        "outputId": "181a176a-e2da-4289-fab9-aa6a2b99545d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m490/490\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Test MAE on holdout: 5.21382\n"
          ]
        }
      ]
    }
  ]
}